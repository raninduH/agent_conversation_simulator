import os
from pinecone import Pinecone, ServerlessSpec
from sentence_transformers import SentenceTransformer
from dotenv import load_dotenv
import time
from datetime import datetime
import PyPDF2
import json
import uuid
import io

# Load environment variables from .env file
load_dotenv()

def setup_embedding_model():
    """
    Loads the embedding model and sets it globally.
    This function should be called once when the application starts.
    """
    # Use a pre-trained model from HuggingFace
    model_name = "sentence-transformers/all-MiniLM-L6-v2"
    
    print(f"ğŸ”§ EMBEDDING MODEL SETUP: Starting setup for embedding model '{model_name}'...")
    print(f"ğŸ“… Timestamp: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    try:
        start_time = time.time()
        print(f"â³ Loading SentenceTransformer model '{model_name}'...")
        
        # Load the model directly with SentenceTransformers
        model = SentenceTransformer(model_name)
        
        load_time = time.time() - start_time
        print(f"âœ… EMBEDDING MODEL SETUP COMPLETE!")
        print(f"   ğŸ“Š Model: {model_name}")
        print(f"   â±ï¸  Load time: {load_time:.2f} seconds")
        print(f"   ğŸ¯ Ready for document embedding tasks")
        print("-" * 60)
        
        return model
        
    except Exception as e:
        print(f"âŒ EMBEDDING MODEL SETUP FAILED!")
        print(f"   ğŸš¨ Error: {e}")
        print(f"   ğŸ’¡ Please ensure 'sentence-transformers' and 'torch' are installed")
        print(f"   ğŸ’» Run: pip install sentence-transformers torch")
        print("-" * 60)
        raise

def load_document(file_path):
    """Load document content from various file types."""
    print(f"   ğŸ“„ Loading: {os.path.basename(file_path)}")
    
    try:
        if file_path.lower().endswith('.pdf'):
            # Load PDF file
            with open(file_path, 'rb') as file:
                pdf_reader = PyPDF2.PdfReader(file)
                text = ""
                for page_num, page in enumerate(pdf_reader.pages):
                    page_text = page.extract_text()
                    text += page_text + "\n"
                print(f"      ğŸ“„ PDF pages processed: {len(pdf_reader.pages)}")
                return text.strip()
        else:
            # Load text file
            with open(file_path, 'r', encoding='utf-8', errors='ignore') as file:
                content = file.read()
                print(f"      ğŸ“ Text file loaded successfully")
                return content.strip()
    except Exception as e:
        print(f"      âŒ Failed to load document: {e}")
        return ""

def chunk_text(text, chunk_size=1000, overlap=200):
    """Split text into overlapping chunks."""
    chunks = []
    start = 0
    while start < len(text):
        end = start + chunk_size
        chunk = text[start:end]
        chunks.append(chunk)
        start = end - overlap
        if start >= len(text):
            break
    return chunks

def ingest_agent_documents(agent_id: str):
    """
    Chunks, embeds, and stores documents for a given agent in a unique Pinecone index.
    
    Args:
        agent_id: The unique identifier for the agent.
    """
    print("=" * 80)
    print(f"ğŸš€ STARTING DOCUMENT INGESTION FOR AGENT: {agent_id}")
    print(f"ğŸ“… Timestamp: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("=" * 80)
    
    agent_docs_path = os.path.join("knowledge_base", agent_id)
    
    # Check if documents exist
    print(f"ğŸ“‚ DOCUMENT DISCOVERY:")
    print(f"   ğŸ“ Checking path: {os.path.abspath(agent_docs_path)}")
    
    if not os.path.exists(agent_docs_path):
        print(f"   âŒ Directory does not exist!")
        print(f"   â„¹ï¸  No documents found for agent {agent_id}. Skipping ingestion.")
        print("=" * 80)
        return
    
    files_in_directory = os.listdir(agent_docs_path)
    if not files_in_directory:
        print(f"   âŒ Directory is empty!")
        print(f"   â„¹ï¸  No documents found for agent {agent_id}. Skipping ingestion.")
        print("=" * 80)
        return
    
    print(f"   âœ… Found {len(files_in_directory)} file(s):")
    for i, file in enumerate(files_in_directory, 1):
        file_path = os.path.join(agent_docs_path, file)
        file_size = os.path.getsize(file_path)
        print(f"      {i}. {file} ({file_size:,} bytes)")

    # Check environment variables
    print(f"\nğŸ” ENVIRONMENT VALIDATION:")
    pinecone_api_key = os.getenv("PINECONE_API_KEY")
    pinecone_env = os.getenv("PINECONE_ENV")
    
    if pinecone_api_key:
        print(f"   âœ… PINECONE_API_KEY found (length: {len(pinecone_api_key)} chars)")
    else:
        print(f"   âŒ PINECONE_API_KEY not found!")
        
    if pinecone_env:
        print(f"   âœ… PINECONE_ENV found: {pinecone_env}")
    else:
        print(f"   âŒ PINECONE_ENV not found!")

    if not pinecone_api_key or not pinecone_env:
        print(f"\nâŒ CONFIGURATION ERROR!")
        print(f"   ğŸš¨ PINECONE_API_KEY and PINECONE_ENV must be set in the .env file.")
        print(f"   ğŸ’¡ Please check your .env file configuration")
        print("=" * 80)
        return

    try:
        # Initialize Pinecone
        print(f"\nğŸŒ² PINECONE CONNECTION:")
        print(f"   â³ Initializing Pinecone connection...")
        start_time = time.time()
        
        # Use new Pinecone API
        pc = Pinecone(api_key=pinecone_api_key)
        
        connection_time = time.time() - start_time
        print(f"   âœ… Pinecone initialized successfully!")
        print(f"   â±ï¸  Connection time: {connection_time:.2f} seconds")
        print(f"   ğŸŒ Environment: {pinecone_env}")
        
        # Create index name
        index_name = f"agent-kb-{agent_id.lower().replace('_', '-')}"
        print(f"   ğŸ“‹ Index name: {index_name}")
        
        # Check existing indexes
        print(f"\nğŸ“‹ INDEX MANAGEMENT:")
        print(f"   â³ Checking existing indexes...")
        existing_indexes = pc.list_indexes().names()
        print(f"   ğŸ“Š Found {len(existing_indexes)} existing index(es):")
        for idx in existing_indexes:
            print(f"      - {idx}")
        
        # The dimension for all-MiniLM-L6-v2 is 384
        dimension = 384
        
        if index_name not in existing_indexes:
            print(f"   ğŸ†• Creating new index '{index_name}'...")
            print(f"      ğŸ“ Dimension: {dimension}")
            print(f"      ğŸ“ Metric: cosine")
            
            create_start = time.time()
            pc.create_index(
                name=index_name, 
                dimension=dimension, 
                metric="cosine",
                spec=ServerlessSpec(
                    cloud='aws',
                    region='us-east-1'
                )
            )
            create_time = time.time() - create_start
            
            print(f"   âœ… Index created successfully!")
            print(f"   â±ï¸  Creation time: {create_time:.2f} seconds")
        else:
            print(f"   â™»ï¸  Using existing index '{index_name}'")

        # Connect to index
        print(f"\nğŸ”— INDEX CONNECTION:")
        print(f"   â³ Connecting to index '{index_name}'...")
        
        pinecone_index = pc.Index(index_name)
        
        # Get index stats
        try:
            stats = pinecone_index.describe_index_stats()
            print(f"   âœ… Connected to index successfully!")
            print(f"   ğŸ“Š Index stats:")
            print(f"      ğŸ”¢ Total vectors: {stats.get('total_vector_count', 'Unknown')}")
            print(f"      ğŸ“ Dimension: {stats.get('dimension', 'Unknown')}")
        except Exception as e:
            print(f"   âš ï¸  Connected but couldn't get stats: {e}")

        # Setup embedding model
        print(f"\nğŸ¤– EMBEDDING MODEL SETUP:")
        model = setup_embedding_model()

        # Load and process documents
        print(f"\nğŸ“š DOCUMENT PROCESSING:")
        all_chunks = []
        total_chars = 0
        
        for i, file in enumerate(files_in_directory, 1):
            file_path = os.path.join(agent_docs_path, file)
            print(f"   ğŸ“„ Processing file {i}/{len(files_in_directory)}: {file}")
            
            # Load document content
            content = load_document(file_path)
            if not content:
                print(f"      âš ï¸  Skipping empty or unreadable file")
                continue
                
            char_count = len(content)
            total_chars += char_count
            print(f"      ğŸ“Š Content: {char_count:,} characters")
            
            # Chunk the document
            print(f"      ï¿½ Chunking document...")
            chunks = chunk_text(content, chunk_size=1000, overlap=200)
            print(f"      ğŸ“¦ Created {len(chunks)} chunks")
            
            # Add metadata to chunks
            for j, chunk in enumerate(chunks):
                all_chunks.append({
                    'id': f"{agent_id}_{file}_{j}",
                    'text': chunk,
                    'source': file,
                    'chunk_index': j
                })
        
        print(f"\nğŸ“Š PROCESSING SUMMARY:")
        print(f"   ğŸ“„ Files processed: {len(files_in_directory)}")
        print(f"   ğŸ“ Total characters: {total_chars:,}")
        print(f"   ğŸ“¦ Total chunks: {len(all_chunks)}")

        # Generate embeddings and upload to Pinecone
        print(f"\nğŸ”„ EMBEDDING & UPLOAD:")
        print(f"   â³ Generating embeddings for {len(all_chunks)} chunks...")
        
        batch_size = 100
        uploaded_count = 0
        
        for i in range(0, len(all_chunks), batch_size):
            batch = all_chunks[i:i + batch_size]
            print(f"   ğŸ“¦ Processing batch {i//batch_size + 1}/{(len(all_chunks) + batch_size - 1)//batch_size}")
            
            # Generate embeddings for this batch
            texts = [chunk['text'] for chunk in batch]
            embeddings = model.encode(texts)
            
            # Prepare vectors for upsert
            vectors = []
            for j, (chunk, embedding) in enumerate(zip(batch, embeddings)):
                vectors.append({
                    'id': chunk['id'],
                    'values': embedding.tolist(),
                    'metadata': {
                        'text': chunk['text'],
                        'source': chunk['source'],
                        'chunk_index': chunk['chunk_index']
                    }
                })
            
            # Upload to Pinecone
            pinecone_index.upsert(vectors)
            uploaded_count += len(vectors)
            print(f"      âœ… Uploaded {len(vectors)} vectors (total: {uploaded_count})")
        
        print(f"\nâœ… INGESTION COMPLETED SUCCESSFULLY!")
        print(f"   ğŸ“Š Final results:")
        print(f"      ğŸ¯ Agent: {agent_id}")
        print(f"      ğŸ“‹ Index: {index_name}")
        print(f"      ğŸ“„ Documents processed: {len(files_in_directory)}")
        print(f"      ğŸ“ Total characters: {total_chars:,}")
        print(f"      ğŸ“¦ Chunks created: {len(all_chunks)}")
        print(f"      ğŸ”¢ Vectors uploaded: {uploaded_count}")
        
        # Final index stats
        try:
            final_stats = pinecone_index.describe_index_stats()
            print(f"      ï¿½ Final index vectors: {final_stats.get('total_vector_count', 'Unknown')}")
        except Exception as e:
            print(f"      âš ï¸  Couldn't get final stats: {e}")
            
        print("=" * 80)

    except Exception as e:
        print(f"\nâŒ INGESTION FAILED!")
        print(f"   ğŸš¨ Error: {e}")
        print(f"   ğŸ“‹ Agent: {agent_id}")
        print(f"   ğŸ“ Path: {agent_docs_path}")
        print(f"   ğŸ’¡ Please check your configuration and try again")
        print("=" * 80)
        import traceback
        traceback.print_exc()


def query_pinecone(index_name: str, query: str, top_k: int = 3):
    """
    Query a Pinecone index for relevant documents.
    
    Args:
        index_name: The name of the Pinecone index
        query: The search query
        top_k: Number of results to return
        
    Returns:
        List of dictionaries containing relevant document chunks
    """
    print(f"\nğŸ” KNOWLEDGE BASE QUERY:")
    print(f"   ğŸ“‹ Index: {index_name}")
    print(f"   ğŸ” Query: '{query}'")
    print(f"   ğŸ”¢ Requesting top {top_k} results")
    print(f"   ğŸ“… Timestamp: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    try:
        # Check environment variables
        pinecone_api_key = os.getenv("PINECONE_API_KEY")
        pinecone_env = os.getenv("PINECONE_ENV")
        
        if not pinecone_api_key or not pinecone_env:
            print(f"   âŒ Missing Pinecone credentials!")
            return []
        
        print(f"   âœ… Pinecone credentials found")
        
        # Initialize Pinecone
        print(f"   â³ Connecting to Pinecone...")
        start_time = time.time()
        
        # Use new Pinecone API
        pc = Pinecone(api_key=pinecone_api_key)
        
        connection_time = time.time() - start_time
        print(f"   âœ… Connected to Pinecone ({connection_time:.2f}s)")
        
        # Check if index exists
        existing_indexes = pc.list_indexes().names()
        if index_name not in existing_indexes:
            print(f"   âŒ Index '{index_name}' not found!")
            print(f"   ğŸ“‹ Available indexes: {existing_indexes}")
            return []
        
        print(f"   âœ… Index '{index_name}' found")
        
        # Connect to index
        pinecone_index = pc.Index(index_name)
        
        # Check index stats
        try:
            stats = pinecone_index.describe_index_stats()
            vector_count = stats.get('total_vector_count', 0)
            print(f"   ğŸ“Š Index contains {vector_count} vectors")
            
            if vector_count == 0:
                print(f"   âš ï¸  Index is empty - no documents to search!")
                return []
                
        except Exception as e:
            print(f"   âš ï¸  Couldn't get index stats: {e}")
        
        # Setup embedding model and encode query
        print(f"   â³ Encoding query...")
        model = setup_embedding_model()
        query_embedding = model.encode([query])[0].tolist()
        
        # Perform query
        print(f"   ğŸ” Executing search...")
        query_start = time.time()
        
        search_results = pinecone_index.query(
            vector=query_embedding,
            top_k=top_k,
            include_metadata=True
        )
        
        query_time = time.time() - query_start
        print(f"   â±ï¸  Query completed in {query_time:.2f} seconds")
        
        # Process results
        results = []
        if search_results.matches:
            print(f"   âœ… Found {len(search_results.matches)} relevant result(s):")
            
            for i, match in enumerate(search_results.matches, 1):
                score = match.score
                content = match.metadata.get('text', 'No content available')
                source = match.metadata.get('source', 'Unknown source')
                
                print(f"      {i}. Score: {score:.4f} | Source: {source} | Content: {content[:100]}...")
                
                results.append({
                    "content": content,
                    "score": score,
                    "source": source,
                    "rank": i
                })
        else:
            print(f"   âŒ No relevant results found")
            
        print(f"   ğŸ¯ Returning {len(results)} result(s)")
        return results
        
    except Exception as e:
        print(f"   âŒ Query failed: {e}")
        import traceback
        traceback.print_exc()
        return []


class KnowledgeManager:
    """Main class for managing knowledge base operations."""
    
    def __init__(self):
        print(f"ğŸ§  KNOWLEDGE MANAGER INITIALIZED")
        print(f"   ğŸ“… Timestamp: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        try:
            setup_embedding_model()
        except Exception as e:
            print(f"   âš ï¸  Warning: Embedding model setup failed: {e}")
    
    def ingest_agent_documents(self, agent_id: str):
        """Wrapper method for document ingestion."""
        return ingest_agent_documents(agent_id)
    
    def query_pinecone(self, index_name: str, query: str, top_k: int = 3):
        """Wrapper method for querying Pinecone."""
        return query_pinecone(index_name, query, top_k)

